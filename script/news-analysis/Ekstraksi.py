# Import package yang diperlukan
import csv
import pandas as pd
import json
import spacy
import re
from spacy.lang.en import English
from spacy.pipeline import EntityRuler
from spacy import displacy
from collections import Counter

# Import data yg akan dilakukan ekstraksi informasi
data = pd.read_csv("data/desa.csv", encoding='utf-8', index_col=0)
ekstrak = pd.read_csv("hasil_rbf.csv", index_col=0)
file_reader = data[data['Provinsi'] == 'DKI Jakarta'].reset_index().iloc[:, 1:]
kab = file_reader['Kabupaten'].drop_duplicates().reset_index()['Kabupaten']
kec = file_reader['Kecamatan'].drop_duplicates().reset_index()['Kecamatan']
des = file_reader['Desa'].drop_duplicates().reset_index()['Desa']

# Membuat pattern untuk ekstraksi lokasi
patterns, patterns1, patterns2 = [], [], [
    {'label': 'ID', 'pattern': 'Jakarta'}]


def createPattern(data):
    patte = []
    for pp in data:
        for ss in pp.split(" ("):
            pat = []
            if ss.__contains__(" / "):
                #pat += [{'lower':s.lower().replace(")", "")} for sss in ss.split(" / ") for s in sss.split()]
                patte += [{'label': 'GPE', 'pattern': ss.replace(" / ", "")}]
            elif ss.__contains__("/"):
                #pat += [{'lower':s.lower().replace(")", "")} for sss in ss.split("/") for s in sss.split()]
                patte += [{'label': 'GPE', 'pattern': ss.replace("/", "")}]
            else:
                # pat += [{'lower':s.lower().replace(")", "")} for s in ss.split()]
                patte += [{'label': 'GPE', 'pattern': ss.replace(")", "")}]
            # patte.append({'label':'ORG', 'pattern':pat})
    return patte


patterns += createPattern(kec)
patterns += createPattern(kab)
patterns += createPattern(des)

# Memanggil fungsi nlp untuk memulai ekstraksi informasi
nlp = spacy.blank('en')

# Menambahkan daftar lokasi pada spacy
ruler = EntityRuler(nlp)
ruler.add_patterns(patterns)
nlp.add_pipe(ruler)

# Import data konten berita yg akan dilakukan ekstraksi informasi
files = open('data/content_berita.csv', 'r', encoding='utf-8')
file_reader = csv.reader(files)

# Ekstraksi Lokasi
lokasi = [list(dict.fromkeys([x.text for x in nlp(row['filtering1']).ents]))
          for idx, row in file_reader.iterrows()]

# Ekstraksi Tanggal


def deteksi_tanggal(stc, wrd=False):
    if wrd:
        sentences = stc.split()
        return [w for ss in sentences for w in re.findall("\d+/\d+/\d+", ss) if w]
    else:
        return [w for w in re.findall("\d+/\d+/\d+", stc) if w]


tanggal = [list(dict.fromkeys(deteksi_tanggal(row['filtering1'])))
           for idx, row in file_reader.iterrows()]


# Menggabungkan data hasil ekstraksi
file_reader['lokasi'] = lokasi
file_reader['tanggal'] = tanggal

hasil = file_reader[['filtering1', 'rbf', 'lokasi',
                     'tanggal']].reset_index().iloc[:, 1:]
h = hasil[hasil['rbf'] == 1].reset_index().iloc[:, 1:]
result = h[h.tanggal.map(len) > 0].reset_index().iloc[:, 1:]
result['c'] = [1 if 'Jakarta' in loc else 0 for loc in result['lokasi']]

res = result[result['c'] == 1].reset_index().iloc[:, 1:-1]
res = res[res.lokasi.map(len) > 1].reset_index().iloc[:, 1:]

# Data hasil ekstraksi
fix = res.drop_duplicates().reset_index().iloc[:, 1:]
fix.to_csv("siap dipetakan_new_80%.csv")
