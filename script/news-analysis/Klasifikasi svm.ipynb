{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasifikasi Teks (NLP) menggunakan Naive Bayes dan SVM dengan Python\n",
    "# https://medium.com/@arifwc/klasifikasi-teks-nlp-menggunakan-naive-bayes-dan-svm-dengan-python-3411ca933c91"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langkah 1 — Import library yang dibutuhkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, numpy as np, pandas as pd, matplotlib\n",
    "from sklearn import preprocessing, model_selection, naive_bayes, svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from matplotlib import pyplot as plt\n",
    "# import seaborn as sns\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langkah 2 — Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langkah 3 — Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_csv('D:/Kuliah/Skripsi/NER/Labelling/klasifikasi/berita_banjir.csv', sep = ',', index_col=0)\n",
    "dt = dt.dropna().reset_index()\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langkah 4 — Data Preprocessing\n",
    "## Dalam langkah ini terdapat beberapa bagian yang harus dilewati yaitu :\n",
    "### Menghilangkan tanda baca dan angka\n",
    "### Menghilangkan stopword\n",
    "### Melakukan stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menteri Luar Negeri (Menlu) Retno Marsudi mengatakan penyimpanan vaksin akan dilaksanakan sesuai dengan protokol dari WHO Artikel Selengkapnya: Total Vaksin Sinovac Jadi 3 Juta 2\n",
      "Artikel Selengkapnya: Video Karangan Bunga di Markas TNI-Polri Jabar 3\n",
      "Artikel Selengkapnya: Wisatawan Menuju Puncak Diputar Balik 4\n",
      "Artikel Selengkapnya: Banjir 1,5 Meter Terjang Jambi 5\n",
      "Artikel Selengkapnya: 11 Titik Perbatasan Jakarta Disekat Saat Malam Tahun Baru\n"
     ]
    }
   ],
   "source": [
    "for d in dt['content'][3].split(\". \"):\n",
    "    if d.__contains__(\"Selengkapnya: \"):\n",
    "        print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dt['content'][3].split(\". \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filteringBerita(stc, keyword):\n",
    "    lw = str(stc).split(\". \")\n",
    "    idx = 0\n",
    "    for c in str(stc).split(\". \"):\n",
    "        if str(c).__contains__(keyword):\n",
    "            lw.pop(idx)\n",
    "            idx-=1\n",
    "        idx+=1\n",
    "    return \". \".join(lw)\n",
    "\n",
    "\n",
    "\n",
    "def filterBerita(stc):\n",
    "    lw = str(stc).split(\". \")\n",
    "    idx = 0\n",
    "    for c in str(stc).split(\". \"):\n",
    "        if c.lower().__contains__(\"covid\") or c.lower().__contains__(\"vaksin\") or c.lower().__contains__(\"berita menarik lainnya\") or c.lower().__contains__(\"berikut top\") or c.__contains__(\"Front Pembela Islam\") or c.lower().__contains__(\"karangan bunga\") or c.lower().__contains__(\"rapid\") or c.lower().__contains__(\"kartu identitas\") or c.lower().__contains__(\"corona\") or c.lower().__contains__(\"kartu identitas\"):\n",
    "            lw.pop(idx)\n",
    "            idx-=1\n",
    "        idx+=1\n",
    "    return \". \".join(lw)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['filtering1'] = [filteringBerita(c, \"Selengkapnya: \") for c in dt['content']]\n",
    "dt['filtering1'] = [filteringBerita(c, \"Tonton video\") for c in dt['filtering1']]\n",
    "dt['filtering1'] = [filterBerita(c) for c in dt['filtering1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "idx = 0\n",
    "for c in dt['filtering1']:\n",
    "    if len(c.split(\". \"))>25:\n",
    "        if dt['kategori0'][idx]==\"Banjir\":\n",
    "            print(idx)\n",
    "            res.append(idx)\n",
    "    idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = dt[dt['content'].str.len() >100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = dt.reset_index().iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtt = dt.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:/Kuliah/Skripsi/SVM/stopwords-id.txt\") as f:\n",
    "    sww = f.readlines()\n",
    "sw = [s.replace(\"\\n\",\"\") for s in sww]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation_and_number(text):\n",
    "    '''a function for removing punctuation'''\n",
    "    import string\n",
    "    import re\n",
    "    text = str(text)\n",
    "    for sp in string.punctuation:\n",
    "        text = text.replace(sp, \" \")\n",
    "    text = re.sub(r\"\\d+\",\"\",text)    \n",
    "    return text.replace('/\\s\\s+/g', ' ')\n",
    "\n",
    "def stopwords(text):\n",
    "    text = [word.lower() for word in text.split()]\n",
    "    for word in text:\n",
    "        for stop in sw:\n",
    "            if word==stop:\n",
    "                text.remove(word)\n",
    "    text = \" \".join(text)\n",
    "    text = re.sub(r'(.+?)\\1+', r'\\1',text)\n",
    "    return text\n",
    "\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "def stemming(text):\n",
    "    \n",
    "    text = [stemmer.stem(word) for word in text.split()]\n",
    "    return \" \".join(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in dtt.iterrows():\n",
    "    if len(str(row['content']))>23:\n",
    "        a =  a.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.reset_index().iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = a[['content','kategori0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>kategori0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Banjir melanda enam desa di Kabupaten Pasuruan...</td>\n",
       "      <td>Banjir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jalanan di kawasan MH Thamrin dan Sudirman, Ja...</td>\n",
       "      <td>Bukan Banjir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Polda Metro Jaya mengingatkan masyarakat agar ...</td>\n",
       "      <td>Bukan Banjir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sebanyak 1,8 juta vaksin COVID-19 tahap kedua ...</td>\n",
       "      <td>Banjir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tanggul penahan limpasan Sungai Tuntang , Kabu...</td>\n",
       "      <td>Banjir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7919</th>\n",
       "      <td>- Ruas Jalan TB Simatupang Jakarta Selatan se...</td>\n",
       "      <td>Banjir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7920</th>\n",
       "      <td>- Hujan deras yang mengguyur pada sore hari i...</td>\n",
       "      <td>Banjir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7921</th>\n",
       "      <td>- Hujan deras yang mengguyur Jakarta pada sor...</td>\n",
       "      <td>Banjir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7922</th>\n",
       "      <td>- Banjir yang merendam Desa Banjareja, Kecama...</td>\n",
       "      <td>Banjir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7923</th>\n",
       "      <td>- Memasuki musim hujan, Pemkot Bandung mulai ...</td>\n",
       "      <td>Bukan Banjir</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7924 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content     kategori0\n",
       "0     Banjir melanda enam desa di Kabupaten Pasuruan...        Banjir\n",
       "1     Jalanan di kawasan MH Thamrin dan Sudirman, Ja...  Bukan Banjir\n",
       "2     Polda Metro Jaya mengingatkan masyarakat agar ...  Bukan Banjir\n",
       "3     Sebanyak 1,8 juta vaksin COVID-19 tahap kedua ...        Banjir\n",
       "4     Tanggul penahan limpasan Sungai Tuntang , Kabu...        Banjir\n",
       "...                                                 ...           ...\n",
       "7919   - Ruas Jalan TB Simatupang Jakarta Selatan se...        Banjir\n",
       "7920   - Hujan deras yang mengguyur pada sore hari i...        Banjir\n",
       "7921   - Hujan deras yang mengguyur Jakarta pada sor...        Banjir\n",
       "7922   - Banjir yang merendam Desa Banjareja, Kecama...        Banjir\n",
       "7923   - Memasuki musim hujan, Pemkot Bandung mulai ...  Bukan Banjir\n",
       "\n",
       "[7924 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtt['content_remove_punctuation_and_number'] = dtt['filtering1'].apply(remove_punctuation_and_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtt['content_stopwords'] = dtt['content_remove_punctuation_and_number'].apply(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtt['content_stemming'] = dtt['content_stopwords'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtt.to_csv(\"D:/Kuliah/Skripsi/SVM/data_clean1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"D:/Kuliah/Skripsi/SVM/data_clean1.csv\", index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4344\n",
       "1    3547\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langkah 5 — Analisa hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "banjir_data = data[data['kategori0']=='Banjir']\n",
    "bukan_banjir_data = data[data['kategori0']=='Bukan Banjir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "for c in data['kategori0']:\n",
    "    if c=='Banjir':\n",
    "        label.append(1)\n",
    "    else:\n",
    "        label.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langkah 6 — Menyiapkan data training dan testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split( data['content_stemming'], data['label'], test_size=0.3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langkah 7 — Word Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Vectorization\n",
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect.fit(data['content_stemming'])\n",
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(Test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langkah 8 -- Klasifikasi SVM menggunakan kernel linear, polinomial, dan rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion = [0.4, 0.3, 0.2, 0.1]\n",
    "cc = [0.001, 0.01, 0.1, 1, 5, 10, 50, 100, 1000]\n",
    "kernel = ['linear','poly','rbf']\n",
    "res1 = []\n",
    "\n",
    "for p in proportion:\n",
    "    Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split( data['content_stemming'],\n",
    "                                                                        data['label'], test_size=p)\n",
    "    Tfidf_vect = TfidfVectorizer(max_features=50000)\n",
    "    Tfidf_vect.fit(data['content_stemming'])\n",
    "    Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "    Test_X_Tfidf = Tfidf_vect.transform(Test_X)\n",
    "    for ccc in cc:\n",
    "        for k in kernel:\n",
    "            if k==\"rbf\":\n",
    "                model_svm = svm.SVC(C=ccc, kernel=k, gamma = 1)\n",
    "            else:\n",
    "                model_svm = svm.SVC(C=ccc, kernel=k)\n",
    "            model_svm.fit(Train_X_Tfidf,Train_Y)\n",
    "\n",
    "            pred_linear = model_svm.predict(Train_X_Tfidf)\n",
    "            predictions_SVM = model_svm.predict(Test_X_Tfidf)\n",
    "            # Use accuracy_score function to get the accuracy\n",
    "            ts = accuracy_score(predictions_SVM, Test_Y)*100\n",
    "            print(f\"SVM {k} {p} Accuracy Score -> \",ts)\n",
    "            print(confusion_matrix(Test_Y, predictions_SVM))\n",
    "            print(classification_report(Test_Y, predictions_SVM))\n",
    "            print(\"----------------------------------------\")\n",
    "            #print(\"SVM linear Data Training Score -> \", accuracy_score(pred_linear, Train_Y)*100)\n",
    "            res1.append({\"training accuracy\": accuracy_score(pred_linear, Train_Y)*100, \n",
    "                         \"testing accuracy\":ts, \"proportion\":p, \"c\":ccc, \"kernel\":k})\n",
    "\n",
    "pd.DataFrame(res1).to_csv(\"Reporting2.csv\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
